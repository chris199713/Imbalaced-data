{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21484\\270786113.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.countplot(x = 'Class', data = df, palette = 'pastel')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6,8))\n",
    "ax = sns.countplot(x = 'Class', data = df, palette = 'pastel')\n",
    "for count in ax.containers:\n",
    "    ax.bar_label(count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genuine: 99.82725143693798 %\n",
      "fraud: 0.1727485630620034 %\n"
     ]
    }
   ],
   "source": [
    "neg_per = df['Class'].value_counts()[0] / len(df) * 100\n",
    "pos_per = df['Class'].value_counts()[1] / len(df) * 100\n",
    "print(f'Genuine: {neg_per} %')\n",
    "print(f'fraud: {pos_per} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283726 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[283726 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "df.drop('Time', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.158900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.139886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.350252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>-0.254325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>-0.082239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.313391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.513290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283726 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.244200   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.342584   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  1.158900   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.139886   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.073813   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.350252   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527 -0.254325   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561 -0.082239   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.313391   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  0.513290   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[283726 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fearture_scaling(df,col):\n",
    "    features = df[col]\n",
    "    scaler = StandardScaler().fit(features.values.reshape(-1,1))\n",
    "    features = scaler.transform(features.values.reshape(-1,1))\n",
    "    df[col] = features\n",
    "\n",
    "    return df\n",
    "fearture_scaling(df,col = 'Amount')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split\n",
    "Stratified splitting means that when you generate a training / validation dataset split, it will attempt to keep the same percentages of classes in each split.\n",
    "Below shows to splitting tachnique one without stratify and one with. The percentage of Class is printed to show proportion after splitting. With stratify keeps the class proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class'], axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998333\n",
      "1    0.001667\n",
      "Name: Class, dtype: float64\n",
      "0    0.998332\n",
      "1    0.001668\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.3)\n",
    "print(y_train.value_counts() / len(y_train))\n",
    "print(y_test.value_counts() / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998333\n",
      "1    0.001667\n",
      "Name: Class, dtype: float64\n",
      "0    0.998332\n",
      "1    0.001668\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify = y, test_size= 0.3)\n",
    "print(y_train.value_counts() / len(y_train))\n",
    "print(y_test.value_counts() / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified cross validation \n",
    "Cross validation is used to evaluate model \n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into k groups\n",
    "3. For each unique group:\n",
    "    * Take the group as a hold out or test data set\n",
    "    * Take the remaining groups as a training data set\n",
    "    * Fit a model on the training set and evaluate it on the test set\n",
    "    * Retain the evaluation score and discard the model\n",
    "4. Summarize the skill of the model using the sample of model evaluation scores\n",
    "\n",
    "Note: The training happens mutiple times, the model is the same but model parameter is trained for every loop. It can be used for hyper parameter search or for model selection, to compare if SVM, Logitsic regression, or Radom forest is the better algo for a certain task.\n",
    "\n",
    "Using the stratified K fold technqiue makes sure the class proportion stays the same as the whole dataset inside each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kf = StratifiedKFold(n_splits=5, shuffle = False)\n",
    "rf = RandomForestClassifier(n_estimators=50,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "recall (Sensitivity): TP / (TP + FN) -> The number of positives that were corretly classified over all positive cases. How sentitive is the model to positive cases. Recall should be used when having false negatives is more costly than having false positive. In this use case of detecting credit card fraud, It's more important to catch a fraud case when it truly is fraud, which means the cost of having a false negative is much higher than having a false positive (classifying a case as fraud when it is not).\n",
    "\n",
    "precision: TP / (TP + FP) -> The number of positives that were corretly classified over all cases that were classified as positive. How correct our model is when it predicts a case to be positive. Precision should be used when having false positives is more costly than having false negatives. EX: In a YouTube recommendation system, educing the number of false positives is of utmost importance. False positives here represent videos that the user does not like, but YouTube is still recommending them. False negatives are of lesser importance here since the YouTube recommendations should only contain videos that the user is more likely to click on. If the user sees recommendations that are not of their liking, they will close the application, which is not what YouTube desires. Most automated marketing campaigns require a high precision value to ensure that a large number of potential customers will interact with their survey or be interested to learn more. Or an easier example would be in a zombie apocalypse. You would try to accept as many healthy people as you can into your safe zone, but you really dont want to mistakenly pass a zombie. The true positive is this case is a healthy person and false positive a zombie. It is more important to avoid zombies than accepting more healthy people. So you create a method that causes some of the healthy people mistakenly not to get into the safe zone, but this is the cost of not letting a zombie in.\n",
    "\n",
    "F1 score: 2(precision*recall / (precision + recall)) -> F1 score is the harmonic mean of precision and recall, and is used when false negatives and false positves are eqaully costly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m----> 2\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratified_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(rf,X_train,y_train,cv=stratified_kf,scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall scores are: [0.78787879 0.71212121 0.80597015 0.72727273 0.8030303 ]\n",
      "Average Cross Validation Recall scores is: 0.7672546359113523\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross Validation Recall scores are: {score}')\n",
    "print(f'Average Cross Validation Recall scores is: {score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search using GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# 'max_depth':[4,8]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m }\n\u001b[1;32m----> 5\u001b[0m grid_rf \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstratified_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':[50,100],\n",
    "    # 'max_depth':[4,8]\n",
    "}\n",
    "grid_rf = GridSearchCV(rf, param_grid=params,cv = stratified_kf,scoring='recall').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 50}\n",
      "Best score: 0.7945725915875169\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', grid_rf.best_params_)\n",
    "print('Best score:', grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and evaluate model on y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = grid_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_hat)\n",
    "rf_Recall = recall_score(y_test, y_hat)\n",
    "rf_Precision = precision_score(y_test, y_hat)\n",
    "rf_f1 = f1_score(y_test, y_hat)\n",
    "rf_accuracy = accuracy_score(y_test, y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Under/Oversampling</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.99946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Random Forest with    Recall  Precision  F1 Score  Accuracy\n",
       "0  No Under/Oversampling  0.704225   0.961538  0.813008   0.99946"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(rf_Recall, rf_Precision, rf_f1, rf_accuracy)]\n",
    "\n",
    "rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "rf_score.insert(0, 'Random Forest with', 'No Under/Oversampling')\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, we can see that the Accuracy is extremely high, but this is due to our imbalaced dataset. Since in our use case (detecting credict cardfraud), having false negative (classifying fraud as not fraud) is more costly than having false positive(classyfing not fraud as fraud),we will use  recall score as the evaluation metric.\n",
    "We will try to beat the baseline model 70.4% recall score in following models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample\n",
    "Two technqiues will be done to resample the dataset.\n",
    "- Oversampling: Randomly duplicate examples in the minority class.\n",
    "- Undersampling: Randomly delete examples in the majority class.\n",
    "\n",
    "**Change to the class distribution should be only applied to the training dataset. The intent is to influence the fit of the models. The resampling is not applied to the test or holdout dataset used to evaluate the performance of a model.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_os = RandomOverSampler()\n",
    "random_us = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_Over = random_os.fit_resample(X_train,y_train)\n",
    "# The fitted data only contains the traninig data and not the testing\n",
    "X_under, y_under = random_us.fit_resample(X_train,y_train)\n",
    "# The fitted data only contains the traninig data and not the testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling:\n",
      "Genuine class count: 198277\n",
      "Fraud class count: 198277\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: Class, dtype: float64\n",
      "==================================================================\n",
      "Undersampling:\n",
      "Genuine class count: 331\n",
      "Fraud class count: 331\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: Class, dtype: float64\n",
      "Note: after indersampling the amount of data left to train is very few, not ideal.\n"
     ]
    }
   ],
   "source": [
    "print('Oversampling:')\n",
    "print(f'Genuine class count: {y_Over.value_counts()[0]}')\n",
    "print(f'Fraud class count: {y_Over.value_counts()[1]}')\n",
    "print(y_Over.value_counts() / len(y_Over))\n",
    "print('==================================================================')\n",
    "print('Undersampling:')\n",
    "print(f'Genuine class count: {y_under.value_counts()[0]}')\n",
    "print(f'Fraud class count: {y_under.value_counts()[1]}')\n",
    "print(y_under.value_counts() / len(y_under))\n",
    "print('Note: after indersampling the amount of data left to train is very few, not ideal.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building pipeline\n",
    "5 fold srtratified Cross validattion will split the entire dataset into 5 section with same proportion of classes. Every fold will take turns being the validation set and the training segment will gp through the steps bellow. \n",
    "- Oversample / Undersample the minority / majority class\n",
    "- Train the classifier on the training segment (The oversampled or Undersampled part)\n",
    "- Validate the classifier with the remaining segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline, make_pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_overs_pipeline = make_pipeline(RandomOverSampler(),RandomForestClassifier(n_estimators = 50,random_state=42))\n",
    "random_unders_pipeline = make_pipeline(RandomUnderSampler(),RandomForestClassifier(n_estimators = 50,random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall Scores are: [0.75757576 0.68181818 0.82089552 0.75757576 0.8030303 ]\n",
      "Average Cross Validation Recall score: 0.7641791044776118\n",
      "Cross Validation Recall Scores are: [0.72727273 0.6969697  0.82089552 0.75757576 0.8030303 ]\n",
      "Average Cross Validation Recall score: 0.7611488014473089\n"
     ]
    }
   ],
   "source": [
    "score2 = cross_val_score(random_overs_pipeline, X_train, y_train, scoring='recall', cv=stratified_kf)\n",
    "print(\"Cross Validation Recall Scores are: {}\".format(score2))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score2.mean()))\n",
    "\n",
    "score3 = cross_val_score(random_overs_pipeline, X_train, y_train, scoring='recall', cv=stratified_kf)\n",
    "print(\"Cross Validation Recall Scores are: {}\".format(score3))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score3.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;randomoversampler&#x27;,\n",
       "                                        RandomOverSampler()),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={&#x27;randomforestclassifier__n_estimators&#x27;: [50, 100]},\n",
       "             return_train_score=True, scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;randomoversampler&#x27;,\n",
       "                                        RandomOverSampler()),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={&#x27;randomforestclassifier__n_estimators&#x27;: [50, 100]},\n",
       "             return_train_score=True, scoring=&#x27;recall&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomoversampler&#x27;, RandomOverSampler()),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=50, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('randomoversampler',\n",
       "                                        RandomOverSampler()),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={'randomforestclassifier__n_estimators': [50, 100]},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "\n",
    "grid_over_rf = GridSearchCV(random_overs_pipeline, param_grid=new_params, cv=stratified_kf, scoring='recall',\n",
    "                        return_train_score=True)\n",
    "grid_over_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'randomforestclassifier__n_estimators': 50}\n",
      "Best score: 0.7611488014473089\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', grid_over_rf.best_params_)\n",
    "print('Best score:', grid_over_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = grid_over_rf.best_estimator_.named_steps['randomforestclassifier'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84967     9]\n",
      " [   31   111]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "over_rf_Recall = recall_score(y_test, y_hat)\n",
    "over_rf_Precision = precision_score(y_test, y_hat)\n",
    "over_rf_f1 = f1_score(y_test, y_hat)\n",
    "over_rf_accuracy = accuracy_score(y_test, y_hat)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.78169</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.99953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Random Forest with   Recall  Precision  F1 Score  Accuracy\n",
       "0  Random Oversampling  0.78169      0.925  0.847328   0.99953"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(over_rf_Recall, over_rf_Precision, over_rf_f1, over_rf_accuracy)]\n",
    "\n",
    "over_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "over_rf_score.insert(0, 'Random Forest with', 'Random Oversampling')\n",
    "over_rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;randomundersampler&#x27;,\n",
       "                                        RandomUnderSampler()),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={&#x27;randomforestclassifier__n_estimators&#x27;: [50, 100]},\n",
       "             return_train_score=True, scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;randomundersampler&#x27;,\n",
       "                                        RandomUnderSampler()),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={&#x27;randomforestclassifier__n_estimators&#x27;: [50, 100]},\n",
       "             return_train_score=True, scoring=&#x27;recall&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomundersampler&#x27;, RandomUnderSampler()),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=50, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('randomundersampler',\n",
       "                                        RandomUnderSampler()),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={'randomforestclassifier__n_estimators': [50, 100]},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_under_rf = GridSearchCV(random_unders_pipeline, param_grid=new_params, cv=stratified_kf, scoring='recall',\n",
    "                        return_train_score=True)\n",
    "grid_under_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'randomforestclassifier__n_estimators': 50}\n",
      "Best score: 0.7611488014473089\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', grid_over_rf.best_params_)\n",
    "print('Best score:', grid_over_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = grid_under_rf.best_estimator_.named_steps['randomforestclassifier'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83247  1729]\n",
      " [   15   127]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "under_rf_Recall = recall_score(y_test, y_hat)\n",
    "under_rf_Precision = precision_score(y_test, y_hat)\n",
    "under_rf_f1 = f1_score(y_test, y_hat)\n",
    "under_rf_accuracy = accuracy_score(y_test, y_hat)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.894366</td>\n",
       "      <td>0.068427</td>\n",
       "      <td>0.127127</td>\n",
       "      <td>0.979511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Random Forest with    Recall  Precision  F1 Score  Accuracy\n",
       "0  Random Undersampling  0.894366   0.068427  0.127127  0.979511"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(under_rf_Recall, under_rf_Precision, under_rf_f1, under_rf_accuracy)]\n",
    "\n",
    "under_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "under_rf_score.insert(0, 'Random Forest with', 'Random Undersampling')\n",
    "under_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE(Synthetic Minority Oversampling Technique)\n",
    "SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pipeline = make_pipeline(SMOTE(),RandomForestClassifier(n_estimators = 50,random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall Scores are: [0.77272727 0.75757576 0.85074627 0.81818182 0.83333333]\n",
      "Average Cross Validation Recall score: 0.8065128900949796\n"
     ]
    }
   ],
   "source": [
    "score4 = cross_val_score(smote_pipeline, X_train, y_train, scoring='recall', cv=stratified_kf)\n",
    "print(\"Cross Validation Recall Scores are: {}\".format(score4))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score4.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;smote&#x27;, SMOTE()),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={&#x27;randomforestclassifier__n_estimators&#x27;: [50, 100]},\n",
       "             return_train_score=True, scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;smote&#x27;, SMOTE()),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={&#x27;randomforestclassifier__n_estimators&#x27;: [50, 100]},\n",
       "             return_train_score=True, scoring=&#x27;recall&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE()),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=50, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('smote', SMOTE()),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier(n_estimators=50,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={'randomforestclassifier__n_estimators': [50, 100]},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "\n",
    "smote_rf = GridSearchCV(smote_pipeline, param_grid=new_params, cv=stratified_kf, scoring='recall',\n",
    "                        return_train_score=True)\n",
    "smote_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'randomforestclassifier__n_estimators': 50}\n",
      "Best score: 0.8065128900949796\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', smote_rf.best_params_)\n",
    "print('Best score:', smote_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = smote_rf.best_estimator_.named_steps['randomforestclassifier'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "smote_rf_Recall = recall_score(y_test, y_hat)\n",
    "smote_rf_Precision = precision_score(y_test, y_hat)\n",
    "smote_rf_f1 = f1_score(y_test, y_hat)\n",
    "smote_rf_accuracy = accuracy_score(y_test, y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.999471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Random Forest with    Recall  Precision  F1 Score  Accuracy\n",
       "0  Random Undersampling  0.809859   0.864662  0.836364  0.999471"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(smote_rf_Recall, smote_rf_Precision, smote_rf_f1, smote_rf_accuracy)]\n",
    "\n",
    "smote_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "smote_rf_score.insert(0, 'Random Forest with', 'Random Undersampling')\n",
    "smote_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_balance_rf = RandomForestClassifier(n_estimators=50,random_state=42,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall scores are: [0.71212121 0.62121212 0.80597015 0.74242424 0.75757576]\n",
      "Average Cross Validation Recall score: 0.727860696517413\n"
     ]
    }
   ],
   "source": [
    "score5 = cross_val_score(class_balance_rf, X_train, y_train, cv=stratified_kf, scoring='recall')\n",
    "print(\"Cross Validation Recall scores are: {}\".format(score5))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score5.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_class_balance_rf = GridSearchCV(class_balance_rf, param_grid=params, cv=stratified_kf, \n",
    "                          scoring='recall').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 50}\n",
      "Best score: 0.7308005427408413\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', grid_class_balance_rf.best_params_)\n",
    "print('Best score:', grid_class_balance_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = grid_class_balance_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "balaced_rf_Recall = recall_score(y_test, y_hat)\n",
    "balaced_rf_Precision = precision_score(y_test, y_hat)\n",
    "balaced_rf_f1 = f1_score(y_test, y_hat)\n",
    "balaced_rf_accuracy = accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.999495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Random Forest with    Recall  Precision  F1 Score  Accuracy\n",
       "0  Random Undersampling  0.746479   0.938053  0.831373  0.999495"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(balaced_rf_Recall, balaced_rf_Precision, balaced_rf_f1, balaced_rf_accuracy)]\n",
    "\n",
    "balaced_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "balaced_rf_score.insert(0, 'Random Forest with', 'Random Undersampling')\n",
    "balaced_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve (receiver operating characteristic curve)\n",
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
    "- True positive rate (recall): TP / TP + FN\n",
    "- Flase positive rate: FP / FP + TN\n",
    "An ROC curve plots TPR vs. FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve.\n",
    "\n",
    "AUC (Area under curve) is used to evaluate a classification model. Higher the AUC, the better the model is at predicting 0 classes as 0 and 1 classes as 1.\n",
    "Think of it as whating to have the highest true positive rate possible, while having the lowest flase negative rate possible.\n",
    "**However the ROC is a better metric when the data is balanced.** \n",
    "The reason being the False positive rate considers the True Negatives, and when True Negatives is alarge number, the FPR may be small even though the FP is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the random forest model with class weights is: 0.8873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_curve_score = roc_auc_score(y_test,y_hat)\n",
    "print(f'AUC for the random forest model with class weights is: {roc_curve_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x20549765f40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "RocCurveDisplay.from_estimator(grid_class_balance_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precission recall curve\n",
    "**Used often for Imbalanced data** .The precision recall curve is better than the ROC curve at evaluating models fitting an imbalanced dataset because the precision recall curve does not include True negatives in the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    grid_class_balance_rf, X_test, y_test, name=\"Average precision\")\n",
    "_ = display.ax_.set_title(\"Random Forest with Class weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "A classification data set with skewed class proportions is called imbalanced and it is very common when dealing with machine learning problems. \n",
    "- Credit card fraud detection\n",
    "- Medical disease classification\n",
    "\n",
    "Some techniques to deal with imbalanced dataset includes oversampling and undersampling (Note that these techniques should only be applied on the training dataset to avoid data leakage). Class weight balancing is another technique to fit the model. \n",
    "\n",
    "When dealing with imbalanced dataset \"Accuracy\" metric should be avoided, since a model that only predicts the majority class will have high accuracy. \"Precision\" or \"Recall (Sensitivity)\" should be used depending on the task. If having false negatives are more costly for the task than recall should be used as the evaluation metric. If having false positive is more coslty than precision should be used as the metric.\n",
    "\n",
    "An ROC graph, is a plot that shows model true positive rate vs. false positive rate in different classification thresholds. The larger the AUC(Area under curve) the better the model is at performing the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
